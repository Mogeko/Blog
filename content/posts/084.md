---
title: "我在 2020 年为了让 Rust 编译得更快所做的努力"
date: 2020-05-17T15:15:38+02:00
draft: false
tags: ["rust", "编程之髓"]
categories: ["他山之石"]
featured_image: 
description: 
---
<!-- 
![](https://mogeko.github.io/blog-images/r/084/)
{{< spoiler >}}{{< /spoiler >}}
&emsp;&emsp;
plaintext
 -->

> 这篇文章是 Mozilla 工程师 [Nicholas](https://blog.mozilla.org/nnethercote/author/nnethercotemozillacom/) 对从 2019 年 12 月到现在 (2020 年 5 月) 的工作总结，主要是对提升 Rust 编译器的编译速度而作的改进。
>
> 通过对这篇文章的学习，除了可以了解 Rust 编译器的新特性，更重要的是可以学习一些开发技巧和开发中需要注意的细节。
>
> 原文地址 (英文): [How to speed up the Rust compiler in 2020](https://blog.mozilla.org/nnethercote/2020/04/24/how-to-speed-up-the-rust-compiler-in-2020/)
>
> 作者: [Nicholas Nethercote](https://blog.mozilla.org/nnethercote/author/nnethercotemozillacom/)

我上篇关于我为加快 Rust 编译器的所做工作的总结写于 [2019 年 12 月](https://blog.mozilla.org/nnethercote/2019/12/11/how-to-speed-up-the-rust-compiler-one-last-time-in-2019/)。 是时候更新一波了。

## 增量编译

我新年做的第一件事就是剖析增量编译并对此进行了一些改进。

[#68914](https://github.com/rust-lang/rust/pull/68914): 增量编译通过一个被称为 `SipHasher128` 的哈希算法来处理大量数据，以确定自上一次编译以来更改了哪些代码。此 PR 极大地提升了从输入字节流中提取字节的过程 (通过多次实验以确保它在大端 (big-endian) 和小端 (little-endian) 平台上均可使用），在许多情况下，编译速度最高可提升 13％。 顺便还添加了更多注释来解释该代码中发生了什么，并删除了多个 `unsafe`。

[#69332](https://github.com/rust-lang/rust/pull/69332): **此 PR** 还原了 [#68914](https://github.com/rust-lang/rust/pull/68914) 的一部分，该部分简化了 `u8to64_le` 函数，但同时又使其变得更慢。这对性能没有太大影响，因为它不是一项常用的功能，但我很高兴在还没有被更多人使用的情况下修复了它。 我还添加了一些解释性的注释，因此没有人会犯与我相同的错误！

[#69050](https://github.com/rust-lang/rust/pull/69050): [LEB128 编码](https://en.wikipedia.org/wiki/LEB128)被广泛引用于 Rust 的 crate 存储的元数据 (metadata) 中。Michael Woerister 在之前的 [#46919](https://github.com/rust-lang/rust/pull/46919) 中提升了 (rustc) 编码和解码 LEB128 的速度，但仍有一点慢。这个 PR 减少了编码和解码操作中的循环次数，几乎使它们的速度提高了一倍，并为整体贡献了高达 5％ 的性能提升。 同时还消灭了一个 `unsafe`。在 PR 中，我对所采用的方法进行了[详细说明](https://github.com/rust-lang/rust/pull/69050#issuecomment-585508353)，包括我是如何使用 Callgrind 进行性能分析，并发现可能的改进的。我先后尝试了 18 种不同的方法进行优化 (其中 10 种方法改善了速度)，并且展示了最终的性能结果。

## LLVM bitcode

去年，我从配置文件中注意到 rustc 花费了一些时间来压缩它生成的 LLVM BitCode，尤其是在 Debug 模式下。 我尝试对其进行了改进，不压缩 BitCode，这样可以加快一些速度，但代价是磁盘上已编译工件的大小也显著增加。

然后 Alex Crichton 告诉了我一件很重要的事: 编译器总是为 crate 生成目标代码和 BitCode。正常编译时使用目标代码，而通过链接时间优化 (LTO) 进行编译时则使用 BitCode，这种情况很少见。 用户在这两种情况中二选一，因此同时生成两种代码通常会浪费时间和空间。

在 PR [#66598](https://github.com/rust-lang/rust/pull/66598) 中，我提出了一个简单的方案解决这一问题: 增加一个新的 flag 告诉 rustc 不要生成 LLVM BitCode。然后，只要不使用 LOT，Cargo 便默认使用该 flag 进行编译。经过讨论，我们认为这一方案太过简陋了，于是我们开了个 issue [#66961](https://github.com/rust-lang/rust/issues/66961) 以进行更广泛的讨论。最终通过的方案是使用未压缩的 BitCode 替代压缩 BitCode 储存为目标代码的一部分 (clang 使用的标准格式)，并为 Cargo 引入了一个新的 flag 来禁用 BitCode 的生成，从而摆脱了对压缩 BitCode 的使用。

rustc 对这部分问题的处理有点混乱。编译器可以产生许多不同种类的输出: 汇编代码，目标代码，LLVM IR 和两种不同格式的 LLVM BitCode。 这些输出中的一些格式依赖于其他输出，产生什么样的格式的输出取决于各种命令行选项以及特定的目标平台。内部状态依赖许多布尔值来跟踪最终输出的产品，并且这些布尔值的各种无意义的组合都是可能的。

当我需要理解这些混乱的代码时，我的标准方法是开始重构。我编写了 [#70289](https://github.com/rust-lang/rust/pull/70289)，[#70345](https://github.com/rust-lang/rust/pull/70345) 和 [#70384](https://github.com/rust-lang/rust/pull/70384) 来理清了代码生成的相关逻辑，[#70297](https://github.com/rust-lang/rust/pull/70297)，[#70729](https://github.com/rust-lang/rust/pull/70729) 和 [#71374](https://github.com/rust-lang/rust/pull/71374) 来重构处理命令行选项的相关代码，以及用 [#70644](https://github.com/rust-lang/rust/pull/70644) 来重构模块配置的相关代码。这些更改使我对代码有所了解，我着手简化代码，然后我编写了 [#70458](https://github.com/rust-lang/rust/pull/70458) 以进行主要更改。

同时，Alex Crichton [为 Cargo 编写了新的 flag `-Cembed-bitcode = no`](https://github.com/rust-lang/cargo/pull/8066) (并回答了我的很多问题)。 然后，我[修改了 rustc-perf](https://github.com/rust-lang/rustc-perf/pull/644)，以便它和新版的 rustc 和 Cargo 一起使用，否则，(原本优化性能的) 更改将在 CI 上错误的看起来像性能下降。 最后，我们的新命令行选项经历了的编译器团队全体人员的批准和最终意见征询期，从而可以投入使用。

不幸的是，在进行着陆前测试 (pre-landing tests) 时，我们发现某些链接器无法处理某些特殊部分中的 BitCode。仅在最后一分钟才发现此问题，因为只有那时所有的完整测试才会在所有平台上运行。Oh dear，是时候启动计划 B 了。我最终提交了 [#71323](https://github.com/rust-lang/rust/pull/71323)，该代码回到了最初的简单方案，为 rustc 添加一个名为 `-Cbitcode-in-rlib = no` 的 flag。[**EDIT:** 值得注意的是，libstd 仍使用 `-Cbitcode-in-rlib = yes` 进行编译，这意味着 libstd rlibs 仍同时使用 LTO 和非 LTO 构建。]

最终结果显示，这是我所做的最大的性能改进之一。 对于 Debug 模式下，性能最高提升了 18％。而对于发布版本(opt builds)，我们也可以看到高达 4％ 的性能提升。rlibs 的大小也缩小了约 15-20％。 感谢 Alex 和他提供的所有帮助！

对于直接调用 rustc 而不是使用 Cargo 的进行编译的情况，需要加上 `-Cbitcode-in-rlib = no` 才能应用该特性。

[**EDIT (May 7, 2020):** Alex 通过在生成的代码适当的中添加 “ignore this section, linker” 字样，从而在 [#71528](https://github.com/rust-lang/rust/pull/71528) 中实现了 bitcode-in-object-code-section。他随后在  [#71716](https://github.com/rust-lang/rust/pull/71716) 中将选项名改回了 `-Cembed-bitcode = no`。再次感谢Alex！]

---

**博主也想一口气翻完，但有两个作业临近 Deadline，教授邮件又催得紧，实在是方得一匹，还请大家见谅 \_(:з」∠)\_**

## Miscellaneous improvements

[#67079](https://github.com/rust-lang/rust/pull/67079): Last year in [#64545](https://github.com/rust-lang/rust/pull/64545) I introduced a variant of the `shallow_resolved`  function that was specialized for a hot calling pattern. This PR  specialized that function some more, winning up to 2% on a couple of  benchmarks.

[#67340:](https://github.com/rust-lang/rust/pull/67340) This PR shrunk the size of the `Nonterminal` type from 240 bytes to 40 bytes, reducing the number of `memcpy` calls (because `memcpy` is used to copy values larger than 128 bytes), giving wins on a few benchmarks of up to 2%.

[#68694](https://github.com/rust-lang/rust/pull/68694): `InferCtxt` is a type that contained seven different data structures within `RefCell`s. Several hot operations would borrow most or all of the `RefCell`s, one after the other. This PR grouped the seven data structures together under a single `RefCell` in order to reduce the number of borrows performed, for wins of up to 5%.

[#68790](https://github.com/rust-lang/rust/pull/68790): This PR made a couple of small improvements to the `merge_from_succ` function, giving 1% wins on a couple of benchmarks.

[#68848:](https://github.com/rust-lang/rust/pull/68848) The compiler’s macro parsing code had a loop that instantiated a large, complex value (of type `Parser`) on each iteration, but most of those iterations did not modify the value. This PR changed the code so it initializes a single `Parser` value outside the loop and then uses `Cow` to avoid cloning it except for the modifying iterations, speeding up the `html5ever` benchmark by up to 15%. (An aside: I have used `Cow` several times, and while the concept is straightforward I find the details hard to remember. I have to re-read [the documentation](https://doc.rust-lang.org/std/borrow/enum.Cow.html)  each time. Getting the code to work is always fiddly, and I’m never  confident I will get it to compile successfully… but once I do it works  flawlessly.)

[#69256:](https://github.com/rust-lang/rust/pull/69256) This PR marked with `#[inline]` some small hot functions relating to metadata reading and writing, for 1-5% improvements across a number of benchmarks.

[ #70837:](https://github.com/rust-lang/rust/pull/70837) There is a function called `find_library_crate` that does exactly what its name suggests. It did a lot of repetitive prefix and suffix matching on file names stored as `PathBuf`s. The matching was slow, involving lots of re-parsing of paths within `PathBuf` methods, because `PathBuf`  isn’t really designed for this kind of thing. This PR pre-emptively  extracted the names of the relevant files as strings and stored them  alongside the `PathBuf`s, and changed the matching to use those strings instead, giving wins on various benchmarks of up to 3%.

[#70876](https://github.com/rust-lang/rust/pull/70876): `Cache::predecessors`  is an oft-called function that produces a vector of vectors, and the  inner vectors are usually small. This PR changed the inner vector to a `SmallVec` for some very small wins of up to 0.5% on various benchmarks.

## Other stuff

I [added support](https://github.com/rust-lang-nursery/rustc-perf/pull/620)  to rustc-perf for the compiler’s self-profiler. This gives us one more  profiling tool to use on the benchmark suite on local machines.

I found that using LLD as the linker when building rustc itself  reduced the time taken for linking from about 93 seconds to about 41  seconds. (On my Linux machine I do this by preceding the build command  with `RUSTFLAGS="-C link-arg=-fuse-ld=lld"`.) LLD is a really fast linker! [#39915](https://github.com/rust-lang/rust/issues/39915)  is the three-year old issue open for making LLD the default linker for  rustc, but unfortunately it has stalled. Alexis Beingessner wrote a [nice summary](https://github.com/rust-lang/rust/issues/39915#issuecomment-618726211)  of the current situation. If anyone with knowledge of linkers wants to  work on that issue, it could be a huge win for many Rust users.

## Failures

Not everything I tried worked. Here are some notable failures.

[#69152](https://github.com/rust-lang/rust/pull/69152): As mentioned above, #68914 greatly improved `SipHasher128`,  the hash function used by incremental compilation. That hash function  is a 128-bit version of the default 64-bit hash function used by Rust  hash tables. I tried porting those same improvements to the default  hasher. The goal was not to improve rustc’s speed, because it uses `FxHasher`  instead of default hashing, but to improve the speed of all Rust  programs that do use default hashing. Unfortunately, this caused some  compile-time regressions for complex reasons discussed in detail in the  PR, and so I abandoned it. I did manage to remove some dead code in the  default hasher in [#69471](https://github.com/rust-lang/rust/pull/69471), though.

[#69153](https://github.com/rust-lang/rust/issues/69153): While working on #69152, I tried switching from `FxHasher`  back to the improved default hasher (i.e. the one that ended up not  landing) for all hash tables within rustc. The results were *terrible*;  every single benchmark regressed! The smallest regression was 4%, the  largest was 85%. This demonstrates (a) how heavily rustc uses hash  tables, and (b) how much faster `FxHasher` is than the default hasher when working with small keys.

I tried using [`ahash`](https://crates.io/crates/ahash) for all hash tables within rustc. It is advertised as being as fast as `FxHasher` but higher quality. I found it made rustc a [tiny bit slower](https://github.com/rust-lang/rust/issues/69153#issuecomment-589504301). Also, `ahash` is also not deterministic across different builds, because it uses `const_random!` when initializing hasher state. This could cause extra noise in perf runs, which would be bad. (**Edit:** It would also prevent reproducible builds, which would also be bad.)

I tried changing the `SipHasher128` function used for  incremental compilation from the Sip24 algorithm to the faster but  lower-quality Sip13 algorithm. I got wins of up to 3%, but wasn’t  confident about the safety of the change and so didn’t pursue it  further.

[#69157](https://github.com/rust-lang/rust/pull/69157):  Some follow-up measurements after #69050 suggested that its changes to  LEB128 decoding were not as clear a win as they first appeared. (The  improvements to encoding were still definitive.) The performance of  decoding appears to be sensitive to non-local changes, perhaps due to  differences in how the decoding functions are inlined throughout the  compiler. This PR reverted some of the changes from #69050 because my  initial follow-up measurements suggested they might have been  pessimizations. But then several sets of additional follow-up  measurements taken after rebasing multiple times suggested that the  reversions sometimes regressed performance. The reversions also made the  code uglier, so I abandoned this PR.

[#66405](https://github.com/rust-lang/rust/pull/66405): Each obligation held by `ObligationForest` can be in one of several
 states, and transitions between those states occur at various points. This
 PR reduced the number of states from five to three, and greatly reduced the
 number of state transitions, which won up to 4% on a few benchmarks. However, it ended up causing some [drastic regressions](https://github.com/rust-lang/rust/issues/67454) for some users, so in [#67471 ](https://github.com/rust-lang/rust/pull/67471)I reverted those changes.

[#60608](https://github.com/rust-lang/rust/issues/60608): This issue suggests using `FxIndexSet` in some places where currently an `FxHashMap` plus a `Vec` are used. I tried it for the symbol table and it was a [significant regression](https://github.com/rust-lang/rust/issues/60608#issuecomment-613719700) for a few benchmarks.

## Progress

Since my last blog post, compile times have seen some more good improvements. The following screenshot shows [wall-time changes](https://perf.rust-lang.org/compare.html?start=2019-12-08&end=2020-04-22&stat=wall-time) on the benchmark suite since then (2019-12-08 to 2020-04-22).

[![Table of compiler performance results.](https://ffp4g1ylyit3jdyti1hqcvtb-wpengine.netdna-ssl.com/nnethercote/files/2020/04/Screenshot_2020-04-23-rustc-performance-data.png)](http://blog.mozilla.org/nnethercote/2020/04/24/how-to-speed-up-the-rust-compiler-in-2020/screenshot_2020-04-23-rustc-performance-data/)

The biggest changes are in the synthetic stress tests `await-call-tree-debug`, `wf-projection-stress-65510`, and `ctfe-stress-4`, which aren’t representative of typical code and aren’t that important.

Overall it’s good news, with many improvements (green), some in the  double digits, and relatively few regressions (red). Many thanks to  everybody who helped with all the performance improvements that landed  during this period.

---

译者：[Mogeko](https://mogeko.github.io/about/)

原文作者：[Nicholas Nethercote](https://blog.mozilla.org/nnethercote/author/nnethercotemozillacom/)

原文链接：[How to speed up the Rust compiler in 2020](https://blog.mozilla.org/nnethercote/2020/04/24/how-to-speed-up-the-rust-compiler-in-2020/)

<center>  ·End·  </center>

