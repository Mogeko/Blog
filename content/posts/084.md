---
title: "为了让 Rust 编译得更快，我所做的努力 (2020)"
date: 2020-05-17T15:15:38+02:00 
draft: false
tags: ["rust", "编程之髓"]
categories: ["他山之石"]
featured_image: 
description: 
---
<!-- 
![](https://mogeko.github.io/blog-images/r/084/)
{{< spoiler >}}{{< /spoiler >}}
&emsp;&emsp;
plaintext
 -->

> 这篇文章是 Mozilla 工程师 [Nicholas](https://blog.mozilla.org/nnethercote/author/nnethercotemozillacom/) 对从 2019 年 12 月到现在 (2020 年 5 月) 的工作总结，主要是对提升 Rust 编译器的编译速度而作的改进。
>
> 通过对这篇文章的学习，除了可以了解 Rust 编译器的新特性，更重要的是可以学习一些开发技巧和开发中需要注意的细节。
>
> 原文地址 (英文): [How to speed up the Rust compiler in 2020](https://blog.mozilla.org/nnethercote/2020/04/24/how-to-speed-up-the-rust-compiler-in-2020/)
>
> 作者: [Nicholas Nethercote](https://blog.mozilla.org/nnethercote/author/nnethercotemozillacom/)

我上篇关于我为加快 Rust 编译器的所做工作的总结写于 [2019 年 12 月](https://blog.mozilla.org/nnethercote/2019/12/11/how-to-speed-up-the-rust-compiler-one-last-time-in-2019/)。 是时候更新一波了。

## 增量编译

我新年做的第一件事就是剖析增量编译并对此进行了一些改进。

[#68914](https://github.com/rust-lang/rust/pull/68914): 增量编译通过一个被称为 `SipHasher128` 的哈希算法来处理大量数据，以确定自上一次编译以来更改了哪些代码。此 PR 极大地提升了从输入字节流中提取字节的过程 (通过多次实验以确保它在大端 (big-endian) 和小端 (little-endian) 平台上均可使用），在许多情况下，编译速度最高可提升 13％。 顺便还添加了更多注释来解释该代码中发生了什么，并删除了多个 `unsafe`。

[#69332](https://github.com/rust-lang/rust/pull/69332): **此 PR** 还原了 [#68914](https://github.com/rust-lang/rust/pull/68914) 的一部分，该部分简化了 `u8to64_le` 函数，但同时又使其变得更慢。这对性能没有太大影响，因为它不是一项常用的功能，但我很高兴在还没有被更多人使用的情况下修复了它。 我还添加了一些解释性的注释，因此没有人会犯与我相同的错误！

[#69050](https://github.com/rust-lang/rust/pull/69050): [LEB128 编码](https://en.wikipedia.org/wiki/LEB128)被广泛引用于 Rust 的 crate 存储的元数据 (metadata) 中。Michael Woerister 在之前的 [#46919](https://github.com/rust-lang/rust/pull/46919) 中提升了 (rustc) 编码和解码 LEB128 的速度，但仍有一点慢。这个 PR 减少了编码和解码操作中的循环次数，几乎使它们的速度提高了一倍，并为整体贡献了高达 5％ 的性能提升。 同时还消灭了一个 `unsafe`。在 PR 中，我对所采用的方法进行了[详细说明](https://github.com/rust-lang/rust/pull/69050#issuecomment-585508353)，包括我是如何使用 Callgrind 进行性能分析，并发现可能的改进的。我先后尝试了 18 种不同的方法进行优化 (其中 10 种方法改善了速度)，并且展示了最终的性能结果。

## LLVM bitcode

去年，我从配置文件中注意到 rustc 花费了一些时间来压缩它生成的 LLVM BitCode，尤其是在 Debug 模式下。 我尝试对其进行了改进，不压缩 BitCode，这样可以加快一些速度，但代价是磁盘上已编译工件的大小也显著增加。

然后 Alex Crichton 告诉了我一件很重要的事: 编译器总是为 crate 生成目标代码和 BitCode。正常编译时使用目标代码，而通过链接时间优化 (LTO) 进行编译时则使用 BitCode，这种情况很少见。 用户在这两种情况中二选一，因此同时生成两种代码通常会浪费时间和空间。

在 PR [#66598](https://github.com/rust-lang/rust/pull/66598) 中，我提出了一个简单的方案解决这一问题: 增加一个新的 flag 告诉 rustc 不要生成 LLVM BitCode。然后，只要不使用 LOT，Cargo 便默认使用该 flag 进行编译。经过讨论，我们认为这一方案太过简陋了，于是我们开了个 issue [#66961](https://github.com/rust-lang/rust/issues/66961) 以进行更广泛的讨论。最终通过的方案是使用未压缩的 BitCode 替代压缩 BitCode 储存为目标代码的一部分 (clang 使用的标准格式)，并为 Cargo 引入了一个新的 flag 来禁用 BitCode 的生成，从而摆脱了对压缩 BitCode 的使用。

rustc 对这部分问题的处理有点混乱。编译器可以产生许多不同种类的输出: 汇编代码，目标代码，LLVM IR 和两种不同格式的 LLVM BitCode。 这些输出中的一些格式依赖于其他输出，产生什么样的格式的输出取决于各种命令行选项以及特定的目标平台。内部状态依赖许多布尔值来跟踪最终输出的产品，并且这些布尔值的各种无意义的组合都是可能的。

当我需要理解这些混乱的代码时，我的标准方法是开始重构。我编写了 [#70289](https://github.com/rust-lang/rust/pull/70289)，[#70345](https://github.com/rust-lang/rust/pull/70345) 和 [#70384](https://github.com/rust-lang/rust/pull/70384) 来理清了代码生成的相关逻辑，[#70297](https://github.com/rust-lang/rust/pull/70297)，[#70729](https://github.com/rust-lang/rust/pull/70729) 和 [#71374](https://github.com/rust-lang/rust/pull/71374) 来重构处理命令行选项的相关代码，以及用 [#70644](https://github.com/rust-lang/rust/pull/70644) 来重构模块配置的相关代码。这些更改使我对代码有所了解，我着手简化代码，然后我编写了 [#70458](https://github.com/rust-lang/rust/pull/70458) 以进行主要更改。

同时，Alex Crichton [为 Cargo 编写了新的 flag `-Cembed-bitcode = no`](https://github.com/rust-lang/cargo/pull/8066) (并回答了我的很多问题)。 然后，我[修改了 rustc-perf](https://github.com/rust-lang/rustc-perf/pull/644)，以便它和新版的 rustc 和 Cargo 一起使用，否则，(原本优化性能的) 更改将在 CI 上错误的看起来像性能下降。 最后，我们的新命令行选项经历了的编译器团队全体人员的批准和最终意见征询期，从而可以投入使用。

不幸的是，在进行着陆前测试 (pre-landing tests) 时，我们发现某些链接器无法处理某些特殊部分中的 BitCode。仅在最后一分钟才发现此问题，因为只有那时所有的完整测试才会在所有平台上运行。Oh dear，是时候启动计划 B 了。我最终提交了 [#71323](https://github.com/rust-lang/rust/pull/71323)，该代码回到了最初的简单方案，为 rustc 添加一个名为 `-Cbitcode-in-rlib = no` 的 flag。[**EDIT:** 值得注意的是，libstd 仍使用 `-Cbitcode-in-rlib = yes` 进行编译，这意味着 libstd rlibs 仍同时使用 LTO 和非 LTO 构建。]

最终结果显示，这是我所做的最大的性能改进之一。 对于 Debug 模式下，性能最高提升了 18％。而对于发布版本(opt builds)，我们也可以看到高达 4％ 的性能提升。rlibs 的大小也缩小了约 15-20％。 感谢 Alex 和他提供的所有帮助！

对于直接调用 rustc 而不是使用 Cargo 的进行编译的情况，需要加上 `-Cbitcode-in-rlib = no` 才能应用该特性。

[**EDIT (May 7, 2020):** Alex 通过在生成的代码适当的中添加 “ignore this section, linker” 字样，从而在 [#71528](https://github.com/rust-lang/rust/pull/71528) 中实现了 bitcode-in-object-code-section。他随后在  [#71716](https://github.com/rust-lang/rust/pull/71716) 中将选项名改回了 `-Cembed-bitcode = no`。再次感谢Alex！]

## 其他改进

[#67079](https://github.com/rust-lang/rust/pull/67079): 年在 [#64545](https://github.com/rust-lang/rust/pull/64545) 中，我改进了 `shallow_resolved` 函数，该函数用于热调用模式 (hot calling pattern)。 此 PR 进一步改进了该函数，在几个基准测试中获得了 2％ 的性能提升。

[#67340](https://github.com/rust-lang/rust/pull/67340): 此 PR 将 `Nonterminal` 类型的大小从 240 字节缩减为 40 字节，从而减少了 `memcpy` 被调用的次数 (因为 `memcpy` 用于复制大于 128 字节的值)，在一些基准测试中获得了高达 2％ 的性能提升。

[#68694](https://github.com/rust-lang/rust/pull/68694): `InferCtxt` 中原本包含有七种不同数据结构的 `RefCell`。有几个常用的操作将依次借用大部分或全部 `RefCell`。 该 PR 将七种数据结构归为一个 `RefCell`，以减少执行借用的次数，性能最高提升了 5％。

[#68790](https://github.com/rust-lang/rust/pull/68790): 此 PR 对 `merge_from_succ` 函数进行了一些小改进，在几个基准测试中获得 1％ 的性能提升。

[#68848](https://github.com/rust-lang/rust/pull/68848): 编译器的宏解析代码中包含一个循环，该循环在每次迭代时实例化一个较大的复杂值 (`Parser` 类型)，但是这些迭代中的大多数情况并没有修改该值。该 PR 更改了代码，它在循环外初始化了一个 `Parser`，然后使用 `Cow` 避免克隆它 (除非迭代中修改了该值)，从而使 `html5ever` 基准测试速度提高了 15％。(顺便一提：我已经使用过 `Cow` 好几次了，虽然这个概念很简单，但是我发现我很难记住相关细节。每次都必须重新阅读[文档](https://doc.rust-lang.org/std/borrow/enum.Cow.html)。使代码正常工作总是很麻烦，而且我从来没有信心能让它成功编译……但是每次我写完后它却可以正常工作。)

[#69256](https://github.com/rust-lang/rust/pull/69256): 此 PR 优化了一些与 `#[inline]` 标记相关的读写元数据的常用函数，优化后的性能在多个基准测试中均提高了 1-5％。

[ #70837](https://github.com/rust-lang/rust/pull/70837): 有一个名为 `find_library_crate` 的函数，其功能恰如其名。它对储存在 `PathBufs` 中的文件名进行了很多重复的前缀和后缀匹配。匹配速度很慢，其中涉及到在 `PathBuf` 方法中进行大量路径的重新解析，因为 `PathBuf` 并不是真正为干这种活而设计的。 该 PR 抢先提取了相关文件的名称，并以字符串的形式将其存储在 `PathBuf` 中，然后使用这些字符串作为代替进行匹配，从而在各种基准测试中获得了高达 3％ 的性能提升。

[#70876](https://github.com/rust-lang/rust/pull/70876): `Cache::predecessors`  是一个经常被调用的函数，它为 vectors 产生 vector (这一句不是很懂，不知道翻译对没有，原文是: “produces a vector of vectors”)，而且内部 vector 通常很小。此 PR 将内部 vector 更改为 `SmallVec`；此优化在各种基准测试中获得了一个非常小的性能提升，最高可达 0.5％。

## 其他

我为 rustc-perf 添加了对编译器的自我分析器 (compiler’s self-profiler) 的[支持](https://github.com/rust-lang-nursery/rustc-perf/pull/620)。 这为我们运行在本地计算机上的基准测试套件 (benchmark suite) 提供了一个新的分析工具。

我发现在构建 rustc 时使用 LLD 作为链接器可以将链接所花费的时间从大约 93 秒减少到大约 41 秒。(在我Linux 机器上，我通过在 build 命令之前设置 `RUSTFLAGS ="-C link-arg = -fuse-ld = lld"` 来执行此操作。) LLD 是一个非常快的链接器！[#39915](https://github.com/rust-lang/rust/issues/39915) 是一个已存在了三年的 issue，其讨论使 LLD 成为 rustc 的默认链接器，但不幸的是，它停滞不前。 Alexis Beessner 撰写了一份有关当前情况的不错的摘要。如果任何有相关知识的人能解决这个 issue，对于 Rust 用户来说，这可能是一个巨大的性能提升点。

## 失败案例

并非我尝试过的所有方法都奏效。 这是一些失败案例。

[#69152](https://github.com/rust-lang/rust/pull/69152): 如上所述，[#68914](https://github.com/rust-lang/rust/pull/68914) 大大改进了 `SipHasher128`，它是增量编译中被使用的哈希函数。该哈希函数 Rust 哈希表 (Rust  hash tables) 使用的默认 64 位哈希函数的 128 位版本。 我尝试将这些改进移植到默认哈希器 (hasher) 中。其目的不是提高 rustc 的速度，因为它使用 `FxHasher` 而不是默认哈希，而是要提高所有使用默认哈希的 Rust 程序的速度。不幸的是，由于 PR 中详细讨论的复杂原因，这导致了一些编译时回归 (compile-time regressions)，因此我放弃了它。 但我设法在 [#69471](https://github.com/rust-lang/rust/pull/69471) 删除了默认哈希器中的一些无效代码。

[#69153](https://github.com/rust-lang/rust/issues/69153): While working on #69152, I tried switching from `FxHasher`  back to the improved default hasher (i.e. the one that ended up not  landing) for all hash tables within rustc. The results were *terrible*;  every single benchmark regressed! The smallest regression was 4%, the  largest was 85%. This demonstrates (a) how heavily rustc uses hash  tables, and (b) how much faster `FxHasher` is than the default hasher when working with small keys.

I tried using [`ahash`](https://crates.io/crates/ahash) for all hash tables within rustc. It is advertised as being as fast as `FxHasher` but higher quality. I found it made rustc a [tiny bit slower](https://github.com/rust-lang/rust/issues/69153#issuecomment-589504301). Also, `ahash` is also not deterministic across different builds, because it uses `const_random!` when initializing hasher state. This could cause extra noise in perf runs, which would be bad. (**Edit:** It would also prevent reproducible builds, which would also be bad.)

I tried changing the `SipHasher128` function used for  incremental compilation from the Sip24 algorithm to the faster but  lower-quality Sip13 algorithm. I got wins of up to 3%, but wasn’t  confident about the safety of the change and so didn’t pursue it  further.

[#69157](https://github.com/rust-lang/rust/pull/69157):  Some follow-up measurements after #69050 suggested that its changes to  LEB128 decoding were not as clear a win as they first appeared. (The  improvements to encoding were still definitive.) The performance of  decoding appears to be sensitive to non-local changes, perhaps due to  differences in how the decoding functions are inlined throughout the  compiler. This PR reverted some of the changes from #69050 because my  initial follow-up measurements suggested they might have been  pessimizations. But then several sets of additional follow-up  measurements taken after rebasing multiple times suggested that the  reversions sometimes regressed performance. The reversions also made the  code uglier, so I abandoned this PR.

[#66405](https://github.com/rust-lang/rust/pull/66405): Each obligation held by `ObligationForest` can be in one of several
 states, and transitions between those states occur at various points. This
 PR reduced the number of states from five to three, and greatly reduced the
 number of state transitions, which won up to 4% on a few benchmarks. However, it ended up causing some [drastic regressions](https://github.com/rust-lang/rust/issues/67454) for some users, so in [#67471 ](https://github.com/rust-lang/rust/pull/67471)I reverted those changes.

[#60608](https://github.com/rust-lang/rust/issues/60608): This issue suggests using `FxIndexSet` in some places where currently an `FxHashMap` plus a `Vec` are used. I tried it for the symbol table and it was a [significant regression](https://github.com/rust-lang/rust/issues/60608#issuecomment-613719700) for a few benchmarks.

## Progress

Since my last blog post, compile times have seen some more good improvements. The following screenshot shows [wall-time changes](https://perf.rust-lang.org/compare.html?start=2019-12-08&end=2020-04-22&stat=wall-time) on the benchmark suite since then (2019-12-08 to 2020-04-22).

[![Table of compiler performance results.](https://ffp4g1ylyit3jdyti1hqcvtb-wpengine.netdna-ssl.com/nnethercote/files/2020/04/Screenshot_2020-04-23-rustc-performance-data.png)](http://blog.mozilla.org/nnethercote/2020/04/24/how-to-speed-up-the-rust-compiler-in-2020/screenshot_2020-04-23-rustc-performance-data/)

The biggest changes are in the synthetic stress tests `await-call-tree-debug`, `wf-projection-stress-65510`, and `ctfe-stress-4`, which aren’t representative of typical code and aren’t that important.

Overall it’s good news, with many improvements (green), some in the  double digits, and relatively few regressions (red). Many thanks to  everybody who helped with all the performance improvements that landed  during this period.

---

译者：[Mogeko](https://mogeko.github.io/about/)

原文作者：[Nicholas Nethercote](https://blog.mozilla.org/nnethercote/author/nnethercotemozillacom/)

原文链接：[How to speed up the Rust compiler in 2020](https://blog.mozilla.org/nnethercote/2020/04/24/how-to-speed-up-the-rust-compiler-in-2020/)

<center>  ·End·  </center>
